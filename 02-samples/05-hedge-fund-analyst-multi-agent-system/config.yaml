general:
  name: "Financial-multi-agentic-system"      
  description: "This agentic system shows multi-agent collaboration different financial agents"

# This contains the model information for various agents
# in our multi agentic system
model_information:
  # Represents information about the finance agent
  finance_agent_model_info: 
    # Represents the model id that the agent will use within 
    # the strands agents SDK
    # The finance agent is not a complicated agent but calls a tool that requires
    # code generation. We will power the agent with a small model (Nova Micro), but 
    # will use a larger, more comprehensive model for code generation (view the code gen
    # model info section below)
    model_id: us.amazon.nova-micro-v1:0
    # Represents the inference parameters that the foundation model
    # uses at runtime during inference
    inference_parameters:
      temperature: 0.1
  technical_agent_model_info: 
    # Represents the model id that the agent will use within 
    # the strands agents SDK
    model_id: us.anthropic.claude-3-5-sonnet-20240620-v1:0
    # Represents the inference parameters that the foundation model
    # uses at runtime during inference
    inference_parameters:
      temperature: 0.1
      max_tokens: 512
  market_analysis_agent:
    # Represents the model id that the agent will use within 
    # the strands agents SDK
    model_id: us.anthropic.claude-3-5-sonnet-20240620-v1:0
    # Represents the inference parameters that the foundation model
    # uses at runtime during inference
    inference_parameters:
      temperature: 0.1
      max_tokens: 512

# This is the code generation model that is used within the tool
# to generate code, note that this might be different from the actual
# large language model that powers the agent
code_gen_model_info:
  # Represents the model id that the agent will use within 
  # the strands agents SDK
  model_id: us.anthropic.claude-3-5-sonnet-20240620-v1:0
  # Represents the inference parameters that the foundation model
  # uses at runtime during inference
  inference_parameters:
    temperature: 0.1
    max_tokens: 2048
